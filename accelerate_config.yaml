# Accelerate 配置文件 - 多卡训练
# 使用方法: accelerate launch --config_file accelerate_config.yaml your_script.py

compute_environment: LOCAL_MACHINE

# 分布式训练类型 - 多 GPU 模式 (DDP)
distributed_type: MULTI_GPU  # 使用 DistributedDataParallel 进行多卡训练

# GPU 配置
num_processes: 2  # 使用的 GPU 数量，根据你的实际 GPU 数量调整
gpu_ids: all  # 使用所有可用的 GPU，或者指定具体的 GPU ID，如 [0, 1]
main_process_port: 29500  # 主进程端口

# 混合精度
mixed_precision: bf16  # fp16, bf16, 或 no (bf16 对于大模型更稳定)

# 其他设置
use_cpu: false
dynamo_backend: "NO"  # 不使用 torch.compile

# DDP 特定设置
# 如果遇到 NCCL 超时问题，可以增加这个值
# ddp_timeout: 1800  # 30 分钟

# 如果需要使用 DeepSpeed，可以取消注释以下配置
# deepspeed_config_file: deepspeed_config.json
